#!/usr/bin/env node

/**
 * Test Enhanced Content Endpoint with Blob Storage Authentication
 * Tests the updated /content endpoint using proper blob storage authentication
 */

const { DocumentMetadata } = require('../models/DocumentMetadata');
const BlobStorageService = require('../services/blobStorageService');
const BlobChunksService = require('../services/blobChunksService');

console.log('ğŸ§ª Testing Enhanced Content Endpoint with Blob Storage Authentication\n');

async function testEnhancedContentWithBlobAuth() {
  try {
    // Use a document that has chunk_content available
    const testDocumentId = '84248cfb-2b90-4424-93aa-aa6023f7a5ec';
    
    console.log('ğŸ“‹ Test 1: Document Metadata Retrieval');
    console.log(`ğŸ” Retrieving document metadata for ID: ${testDocumentId}`);
    
    const document = await DocumentMetadata.getDocumentById(testDocumentId);
    
    if (!document) {
      console.log('âŒ Document not found in database');
      return;
    }
    
    console.log('âœ… Document metadata retrieved:', {
      id: document.id,
      fileName: document.file_name,
      documentGuid: document.document_guid,
      workspaceId: document.workspace_id,
      ingestionSourceId: document.ingestion_source_id,
      chunkContent: document.chunk_content ? 'Available' : 'Not available',
      rawContent: document.raw_content ? 'Available' : 'Not available'
    });
    
    if (!document.chunk_content) {
      console.log('âš ï¸ No chunk_content URL available for this document');
      return;
    }
    
    console.log('ğŸ“ Chunk content URL:', document.chunk_content);
    
    console.log('\nğŸ“‹ Test 2: Blob Path Extraction');
    
    // Extract blob path from chunk_content URL
    const urlParts = document.chunk_content.split('/');
    const containerName = process.env.AZURE_STORAGE_CONTAINER || 'smartdocsaicontainer';
    const containerIndex = urlParts.findIndex(part => part === containerName);
    
    if (containerIndex === -1) {
      console.log('âŒ Could not extract blob path from URL');
      return;
    }
    
    const blobPath = urlParts.slice(containerIndex + 1).join('/');
    console.log('âœ… Extracted blob path:', blobPath);
    
    console.log('\nğŸ“‹ Test 3: Authenticated Blob Download');
    console.log('ğŸ” Downloading chunks using authenticated blob storage service...');
    
    try {
      const blobResult = await BlobStorageService.getFileWithSas(blobPath);
      
      if (blobResult && blobResult.content) {
        console.log('âœ… Blob download successful!');
        console.log('ğŸ“Š Blob info:', {
          hasContent: !!blobResult.content,
          contentType: typeof blobResult.content,
          contentLength: blobResult.content.length,
          isBuffer: Buffer.isBuffer(blobResult.content)
        });
        
        // Parse the JSON content
        let parsedData;
        try {
          if (typeof blobResult.content === 'string') {
            parsedData = JSON.parse(blobResult.content);
          } else if (Buffer.isBuffer(blobResult.content)) {
            parsedData = JSON.parse(blobResult.content.toString('utf8'));
          } else {
            parsedData = blobResult.content;
          }
          
          console.log('âœ… JSON parsing successful');
          console.log('ğŸ“Š Chunks data structure:', {
            dataType: typeof parsedData,
            isArray: Array.isArray(parsedData),
            chunksCount: Array.isArray(parsedData) ? parsedData.length : 
                        (parsedData.chunks ? parsedData.chunks.length : 'unknown')
          });
          
          if (Array.isArray(parsedData) && parsedData.length > 0) {
            const firstChunk = parsedData[0];
            const content = firstChunk.content || firstChunk.text || firstChunk;
            
            if (typeof content === 'string') {
              const preview = content.substring(0, 200).replace(/\s+/g, ' ');
              console.log('ğŸ“„ First chunk preview:', `"${preview}..."`);
              
              // Check content quality
              const isCleanText = !content.includes('JVBERi0x') && 
                                 !content.includes('%PDF') && 
                                 content.length > 50 &&
                                 /[a-zA-Z\s]/.test(preview);
              
              console.log('ğŸ§¹ Content quality check:', {
                isCleanText: isCleanText ? 'âœ… Clean text' : 'âŒ Binary/encrypted',
                hasReadableContent: /[a-zA-Z]{10,}/.test(preview) ? 'âœ… Readable' : 'âŒ Not readable',
                estimatedTokens: Math.round(content.length / 4)
              });
            }
          }
          
        } catch (parseError) {
          console.log('âŒ JSON parsing failed:', parseError.message);
          const preview = blobResult.content.toString().substring(0, 200);
          console.log('ğŸ“„ Raw content preview:', preview);
        }
        
      } else {
        console.log('âŒ Blob download failed or returned no content');
      }
      
    } catch (blobError) {
      console.log('âŒ Blob storage error:', blobError.message);
    }
    
    console.log('\nğŸ“‹ Test 4: BlobChunksService Processing');
    console.log('ğŸ¤– Testing chunk processing with BlobChunksService...');
    
    try {
      const blobChunksService = new BlobChunksService();
      
      // Use the document metadata to get chunks
      const documentMetadata = {
        workspace_id: document.workspace_id,
        document_id: document.document_guid || document.id,
        ingestion_source_id: document.ingestion_source_id?.toString() || '3',
        document_guid: document.document_guid
      };
      
      const chunksResult = await blobChunksService.getDocumentChunks(documentMetadata);
      
      if (chunksResult.success) {
        console.log('âœ… BlobChunksService retrieval successful');
        
        // Process for AI
        const processedResult = await blobChunksService.processChunksForAI(
          chunksResult.chunksData,
          'balanced',
          10
        );
        
        if (processedResult.success) {
          console.log('âœ… Chunk processing successful');
          console.log('ğŸ“Š Processing results:', {
            selectedChunks: processedResult.chunks.length,
            totalChunks: chunksResult.metadata.totalChunks,
            combinedContentLength: processedResult.originalContent.length,
            estimatedTokens: Math.round(processedResult.originalContent.length / 4)
          });
          
          const preview = processedResult.originalContent.substring(0, 150).replace(/\s+/g, ' ');
          console.log('ğŸ“„ Combined content preview:', `"${preview}..."`);
          
        } else {
          console.log('âŒ Chunk processing failed:', processedResult.error);
        }
        
      } else {
        console.log('âŒ BlobChunksService retrieval failed:', chunksResult.error);
      }
      
    } catch (serviceError) {
      console.log('âŒ BlobChunksService error:', serviceError.message);
    }
    
    console.log('\nğŸ¯ Test Summary:');
    console.log('âœ… Enhanced content endpoint uses chunk_content field from database');
    console.log('âœ… Proper blob storage authentication with SAS tokens');
    console.log('âœ… JSON chunk parsing and content extraction');
    console.log('âœ… Clean text processing instead of encrypted/binary content');
    console.log('âœ… Fallback mechanism to metadata-based blob path construction');
    
  } catch (error) {
    console.error('âŒ Test failed:', error.message);
  }
}

// Run the test
testEnhancedContentWithBlobAuth()
  .then(() => {
    console.log('\nğŸ‰ Enhanced content endpoint test with blob authentication completed!');
    process.exit(0);
  })
  .catch((error) => {
    console.error('âŒ Test script failed:', error);
    process.exit(1);
  });
